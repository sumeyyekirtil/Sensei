# chatbot_project.py (rag sistem ve arayÃ¼z entegre)

import os
import streamlit as st
from dotenv import load_dotenv

# LangChain BileÅŸenleri
from langchain_google_genai import ChatGoogleGenerativeAI
#from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.embeddings import HuggingFaceEmbeddings # <-- YENÄ° SATIR - api yenilenmesine raÄŸmen limit 0 da olduÄŸu iÃ§in kÃ¼tÃ¼phane import iÅŸlemi yapÄ±ldÄ±
# chatbot_project.py (nihai, temiz, duygu entegrasyonlu versiyon)
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate 
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda # <--- BU SATIR - sorgulama zinciri pipe hatasÄ± iÃ§in

# --- YAPILANDIRMA ---
load_dotenv()
CHROMA_DB_PATH = "./chroma_db" 

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY") 
if not GEMINI_API_KEY:
    st.error("GEMINI_API_KEY bulunamadÄ±. LÃ¼tfen .env dosyanÄ±zÄ± kontrol edin.")
    st.stop()
# --------------------

# --- 1. FONKSÄ°YON: RAG Zincirini Kurma (MANUEL ZÄ°NCÄ°R) ---
@st.cache_resource
def setup_rag_chain():
    """RAG sistemini stabil LangChain bileÅŸenleriyle kurar."""
    try:
        # 1. Embeddings Modeli (Ã‡ok Dilli Yerel Model)
        embeddings_model = HuggingFaceEmbeddings(
            model_name="paraphrase-multilingual-mpnet-base-v2"
            #"yeni model - sorgu - rag - veri seti deÄŸiÅŸiminde chroma db silinmeli yeniden oluÅŸturulmalÄ±dÄ±r"
            #"all-MiniLM-L6-v2" - yabancÄ± dil modeli
        )
            
        # VektÃ¶r Deposu YÃ¼kleniyor
        vector_store = Chroma(
            persist_directory=CHROMA_DB_PATH, 
            embedding_function=embeddings_model
        )

        # Geri Ã‡ekici (Retriever) TanÄ±mlama
        retriever = vector_store.as_retriever(search_kwargs={"k": 5})

        # 2. LLM Modeli (AsÄ±l CevaplayÄ±cÄ±)
        llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash", 
            temperature=0.4, 
            google_api_key=GEMINI_API_KEY
        )

        # 3. DUYGU TERCÃœMANI (PRE-PROCESSING) ZÄ°NCÄ°RÄ°
        
        # 3a. Duygu TercÃ¼manÄ± Prompt'u
        emotion_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", 
         "Sen bir duygu durum tercÃ¼manÄ±sÄ±n. KullanÄ±cÄ±nÄ±n verdiÄŸi ifadeyi sadece bir veya birkaÃ§ film tÃ¼rÃ¼ne Ã§evir. "
         "Ã–RNEK: 'NeÅŸeliyim' -> 'Komedi, Romantik', 'ÃœzgÃ¼nÃ¼m' -> 'Dram', 'Korku filmi Ã¶ner' -> 'Korku'. "
         "EÄŸer kullanÄ±cÄ± hem duygu hem de tÃ¼r belirtiyor ve bunlar Ã§eliÅŸiyorsa (Ã–rnek: 'Mutluyum ama korku filmi izlemek istiyorum'), "
         "**LÃœTFEN TÃœR Ä°STEÄÄ°NÄ° Ã–NCELÄ°KLENDÄ°R VE DÃ–NDÃœR (yani 'Korku' dÃ¶n).** "
         "SADECE virgÃ¼lle ayrÄ±lmÄ±ÅŸ film tÃ¼rlerini dÃ¶ndÃ¼r. BAÅKA HÄ°Ã‡BÄ°R CÃœMLE KURMA. "
         "EÄŸer hiÃ§bir duygu veya tÃ¼r Ã§Ä±karamÄ±yorsan 'Genel' kelimesini dÃ¶ndÃ¼r."
        ),
        ("human", "{emotion_input}"),
    ]
)

        # 3b. Duygu TercÃ¼manÄ± LLM'i
        emotion_llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash", 
            temperature=0.0, # YaratÄ±cÄ±lÄ±ÄŸÄ± sÄ±fÄ±rlÄ±yoruz
            google_api_key=GEMINI_API_KEY
        )

        # 3c. TÃ¼r Ã‡eviri Zinciri
        genre_translator_chain = (
            {"emotion_input": RunnablePassthrough()}
            | emotion_prompt
            | emotion_llm
            | StrOutputParser()
        )

        # 4. YANIT OLUÅTURMA (GENERATION) PROMPT'U
        system_prompt = (
            "Sen bir film Ã¶neri asistanÄ±sÄ±n. YalnÄ±zca saÄŸlanan 'BaÄŸlam' iÃ§erisindeki filmlerle ilgili yanÄ±t ver."
            "YanÄ±tÄ±nÄ± nazik ve kÄ±sa tut, film baÅŸlÄ±klarÄ±nÄ± vurgula."
            "EÄŸer yanÄ±tÄ± BAÄLAM'da bulamÄ±yorsan, 'ÃœzgÃ¼nÃ¼m, aradÄ±ÄŸÄ±n filmi veya bilgiyi veritabanÄ±mda bulamadÄ±m.' de."
            "\n\nBaÄŸlam: {context}"
        )
        
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", system_prompt),
                ("human", "{question}"),
            ]
        )

        # 5. MANUEL RAG ZÄ°NCÄ°RÄ°NÄ° OLUÅTURMA (Duygu Entegre)
        def format_docs(docs):
            # Geri Ã§ekilen belgeleri tek bir string'de birleÅŸtirir
            return "\n\n".join(doc.page_content for doc in docs)

        rag_chain = (
            # 1. KULLANICI SORUSUNU Ã–NCE TÃœR TERCÃœMANINA GÃ–NDER
            RunnablePassthrough.assign(
                query_to_search=genre_translator_chain
            )
            # 2. RETRIEVER'A GÄ°TMEDEN Ã–NCE Ã‡EVRÄ°LEN TÃœRÃœ YENÄ° SORGU OLARAK KULLAN
            .assign(
                # Ã‡evrilen tÃ¼rÃ¼ (query_to_search) retriever'a gÃ¶nder,
                # ardÄ±ndan sonucu RunnableLambda ile format_docs'a aktar.
                context=lambda x: (retriever | RunnableLambda(format_docs)).invoke(x["query_to_search"]),
                
                # Orijinal kullanÄ±cÄ± sorusunu LLM'e gÃ¶ndermek iÃ§in sakla
                question=lambda x: x["emotion_input"]
            )
            # 3. YANIT OLUÅTURMA
            | prompt 
            | llm
            | StrOutputParser()
        )
        
        # SÄ°STEM BURADA RAG ZÄ°NCÄ°RÄ°NÄ° BAÅARILI BÄ°R ÅEKÄ°LDE DÃ–NDÃœRMELÄ°DÄ°R
        return rag_chain

    except Exception as e:
        st.error(f"RAG Zinciri kurulurken bir hata oluÅŸtu: {e}")
        st.stop()


# --- 2. FONKSÄ°YON: Streamlit ArayÃ¼zÃ¼ ---
def main():
    """Ana Streamlit arayÃ¼z fonksiyonu"""
    st.set_page_config(page_title="Sensei - Film Ã–neri AsistanÄ± (RAG)", layout="centered")
    st.title("ğŸ¬ Duygulardan Filmlere AÃ§Ä±lan KapÄ± - Sensei")
    st.caption("VeritabanÄ±mÄ±zdaki filmler hakkÄ±nda sorular sorun (Ã¶rn: 'Ã‡ok mutluyum', 'Aksiyon filmi Ã¶ner').")

    qa_chain = setup_rag_chain() 

    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("BugÃ¼n ruh halin nasÄ±l? Hadi birlikte film gecesi dÃ¼zenleyelim! EÄŸlenceye hazÄ±r mÄ±sÄ±n?"):
        
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("ğŸ¤– Sensei dÃ¼ÅŸÃ¼nÃ¼yor..."):
                answer = ""
                try:
                    # Zinciri sorgulama
                    # qa_chain, Runnable zinciri olduÄŸu iÃ§in invoke() metodu kullanÄ±lÄ±r.
                    answer = qa_chain.invoke({"emotion_input": prompt})
                    #answer = qa_chain.invoke(prompt) --eski prompt
                    
                    st.markdown(answer)
                except Exception as e:
                    # Hata yakalama
                    st.error(f"Sorgulama Zincirinde Hata OluÅŸtu: {e}")
                    answer = "ÃœzgÃ¼nÃ¼m, ÅŸu anda bir hata oluÅŸtu veya aradÄ±ÄŸÄ±n bilgiyi veritabanÄ±mda bulamadÄ±m. (Hata Kodu: {e})"
                    st.markdown(answer)

        st.session_state.messages.append({"role": "assistant", "content": answer})

if __name__ == "__main__":
    main()